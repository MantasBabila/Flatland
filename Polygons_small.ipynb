{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "auxXj2AuGABs"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten, Conv2D, BatchNormalization, Activation, Dropout, MaxPooling2D, Layer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = np.load('/content/flatland_train.npz')\n",
        "X = data['X']\n",
        "y = data['y']\n",
        "\n",
        "y[y != 0] -= 2    # Correct labels so that triangle is mapped to class 1\n",
        "X = X / 255.      # Scale down to range [0, 1]\n",
        "\n",
        "# Construct and train your model (don't forget train/test split and other tricks)\n",
        "# model = ..."
      ],
      "metadata": {
        "id": "WjtnJUs4IYmC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(X):\n",
        "    plt.imshow(X, cmap='gray', vmin=0, vmax=1)\n",
        "    plt.axis('off')\n",
        "\n",
        "def apply_filter(X, F):\n",
        "    x, y = X.shape\n",
        "    filter_x, filter_y = F.shape\n",
        "    X_with_filter = np.zeros(shape=(x - filter_x, y - filter_y))\n",
        "\n",
        "    for i in range(x - filter_x):\n",
        "        for j in range(y - filter_y):\n",
        "            X_with_filter[i, j] = (X[i:(i+filter_x), j:(j+filter_y)] * F).sum()\n",
        "\n",
        "    return X_with_filter"
      ],
      "metadata": {
        "id": "3U5SgdVNbWGc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "         X, y,\n",
        "         test_size = 0.2, random_state = 42\n",
        ")"
      ],
      "metadata": {
        "id": "fHca6sSzPp1T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_black_pixels(img): #previous idea, didn't use it\n",
        "\n",
        "    color = np.minimum(np.min(img[:, 0]), np.min(img[0, :]))\n",
        "\n",
        "    # Get the dimensions of the original image\n",
        "    height, width = img.shape[:2]\n",
        "\n",
        "    # Define the amount of padding\n",
        "    padding_size = 2\n",
        "\n",
        "    # Create a new image with increased dimensions\n",
        "    new_height = height + 2 * padding_size\n",
        "    new_width = width + 2 * padding_size\n",
        "\n",
        "    # Create a black canvas with increased dimensions\n",
        "    new_img = tf.Tensor((new_height, new_width, 1), color, dtype=float64)\n",
        "\n",
        "    # Place the original image at an offset to add black pixels\n",
        "    new_img[padding_size:new_height-padding_size, padding_size:new_width-padding_size] = img\n",
        "\n",
        "    return new_img"
      ],
      "metadata": {
        "id": "TlYOIlzn9fAi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 50, 50, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 50, 50, 1)"
      ],
      "metadata": {
        "id": "9pnIaVWtYHY1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = X_train[12]\n",
        "\n",
        "color = np.minimum(np.min(img[:, 0]), np.min(img[0, :]))\n",
        "\n",
        "color"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcbywGqLGLvy",
        "outputId": "9b0aca09-f4df-4636-efe4-51274fd15a26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(2, 2))\n",
        "plt.imshow(X_train[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "-f7J2YZEZ7dh",
        "outputId": "7b5b24b8-2529-499b-aa85-4d850cd261d7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e51ec18e1a0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import cv2"
      ],
      "metadata": {
        "id": "QOyoBi0rbLWb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def corners(img): #previous idea, didn't use it\n",
        "\n",
        "    # Convert the image to float32\n",
        "    img = np.float32(img)\n",
        "\n",
        "    # Apply Harris corner detection\n",
        "    harris_corners = cv2.cornerHarris(img, blockSize=2, ksize=3, k=0.04)\n",
        "\n",
        "    # Dilate the corners to make them visible\n",
        "    harris_corners = cv2.dilate(harris_corners, None)\n",
        "\n",
        "    # Threshold for an optimal value, it may vary depending on the image\n",
        "    threshold = 0.01 * harris_corners.max()\n",
        "\n",
        "    # Create an image copy to mark the corners\n",
        "    marked_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    marked_img[harris_corners > threshold] = [0, 0, 255]  # Mark corners in red\n",
        "\n",
        "    return marked_img"
      ],
      "metadata": {
        "id": "rPviOga371dY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.float32(X_train[5])\n",
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agg6ePr5DPIC",
        "outputId": "7081d9fe-ce3b-4457-eba4-dd4f2f068df3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 50, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(corners(X_train[6]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "fRR7yn-ZavRY",
        "outputId": "d3849978-1bd4-4dbe-d344-0203899f10df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e51c6b54fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_pixels(image): #previous idea, didn't use it\n",
        "    # Threshold the image: set pixels > 0.1 to 1\n",
        "    threshold_value = 0.1\n",
        "    thresholded_image = np.where(image > threshold_value, 1, 0)\n",
        "\n",
        "    return thresholded_image"
      ],
      "metadata": {
        "id": "tG_q6F1wjmdm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unblur_edge(image): #previous idea, didn't use it\n",
        "    img = np.uint8(image)\n",
        "\n",
        "    # Apply Gaussian blur to the whole image (for demonstration)\n",
        "    blurred = cv2.GaussianBlur(img, (15, 15), 0)\n",
        "\n",
        "    # Perform edge detection using Canny edge detector\n",
        "    edges = cv2.Canny(blurred, 30, 150)\n",
        "\n",
        "    # Dilate the edges to make them more visible\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    dilated_edges = cv2.dilate(edges, kernel, iterations=1)\n",
        "\n",
        "    # Invert the edges to use as a mask\n",
        "    mask = cv2.bitwise_not(dilated_edges)\n",
        "\n",
        "    # Apply deblurring to the edges only\n",
        "    deblurred_edges = cv2.deconvolve(blurred, np.ones((15, 15), np.float32))\n",
        "\n",
        "    # Combine the deblurred edges with the original image using the mask\n",
        "    result = cv2.bitwise_and(image, image, mask=mask)\n",
        "    result += cv2.bitwise_and(deblurred_edges[1], deblurred_edges[1], mask=dilated_edges)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "6oMDaqHnmsR_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "UATptf_b1pA9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rotation_range=45,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "_bhPMgbKAI7P"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = datagen.flow(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size = 256)  #images to generate in a batch"
      ],
      "metadata": {
        "id": "Jcw8PdbCHTYW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(10, kernel_size = (5, 5), input_shape = [50, 50, 1]))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Conv2D(10, kernel_size = (4, 4)))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Conv2D(10, kernel_size = (3, 3)))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(5, activation = 'softmax'))\n",
        "model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "              optimizer = Adam(learning_rate = 3e-4),\n",
        "              metrics = ['accuracy']) # maybe SparseCategoricalAccuracy()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "nxyoZEwBUa2o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82237fc4-dd13-4046-b90b-18fcbc129605"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 46, 46, 10)        260       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 23, 23, 10)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 23, 23, 10)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 20, 20, 10)        1610      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 10, 10, 10)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10, 10, 10)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 10)          910       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 10)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 10)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 160)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                10304     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15329 (59.88 KB)\n",
            "Trainable params: 15329 (59.88 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "id": "1j5muYLX5sdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97ca717-6735-4105-bdda-7b6ca5ee6d46"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - 19s 36ms/step - loss: 1.5056 - accuracy: 0.3780 - val_loss: 1.3162 - val_accuracy: 0.4775\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 1.2355 - accuracy: 0.4747 - val_loss: 1.2122 - val_accuracy: 0.4806\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.1682 - accuracy: 0.4978 - val_loss: 1.1988 - val_accuracy: 0.4875\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.1371 - accuracy: 0.5092 - val_loss: 1.1807 - val_accuracy: 0.5013\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 1.1146 - accuracy: 0.5166 - val_loss: 1.1440 - val_accuracy: 0.5131\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.0847 - accuracy: 0.5353 - val_loss: 1.1233 - val_accuracy: 0.5163\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.0702 - accuracy: 0.5423 - val_loss: 1.0920 - val_accuracy: 0.5356\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 1.0417 - accuracy: 0.5494 - val_loss: 1.0593 - val_accuracy: 0.5344\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 1.0212 - accuracy: 0.5642 - val_loss: 1.1054 - val_accuracy: 0.5294\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 1.0060 - accuracy: 0.5684 - val_loss: 1.0782 - val_accuracy: 0.5419\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.9835 - accuracy: 0.5786 - val_loss: 0.9617 - val_accuracy: 0.5969\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.9573 - accuracy: 0.5981 - val_loss: 0.9641 - val_accuracy: 0.6012\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.9218 - accuracy: 0.6156 - val_loss: 1.0365 - val_accuracy: 0.5600\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.9043 - accuracy: 0.6164 - val_loss: 1.0007 - val_accuracy: 0.5713\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.8714 - accuracy: 0.6330 - val_loss: 0.9182 - val_accuracy: 0.6181\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.8561 - accuracy: 0.6409 - val_loss: 0.9255 - val_accuracy: 0.6106\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.8193 - accuracy: 0.6602 - val_loss: 0.8925 - val_accuracy: 0.6344\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.7988 - accuracy: 0.6627 - val_loss: 0.8749 - val_accuracy: 0.6425\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.7646 - accuracy: 0.6833 - val_loss: 0.9537 - val_accuracy: 0.5813\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.7281 - accuracy: 0.7022 - val_loss: 0.9484 - val_accuracy: 0.5938\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.7175 - accuracy: 0.7111 - val_loss: 0.9656 - val_accuracy: 0.5919\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6882 - accuracy: 0.7177 - val_loss: 0.8528 - val_accuracy: 0.6463\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6780 - accuracy: 0.7228 - val_loss: 0.8664 - val_accuracy: 0.6406\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.6457 - accuracy: 0.7412 - val_loss: 0.8518 - val_accuracy: 0.6394\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.6269 - accuracy: 0.7623 - val_loss: 0.8082 - val_accuracy: 0.6781\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.6114 - accuracy: 0.7605 - val_loss: 0.7204 - val_accuracy: 0.7094\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5929 - accuracy: 0.7703 - val_loss: 0.6964 - val_accuracy: 0.7350\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5645 - accuracy: 0.7848 - val_loss: 0.7764 - val_accuracy: 0.6894\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5537 - accuracy: 0.7875 - val_loss: 0.7563 - val_accuracy: 0.6900\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.5375 - accuracy: 0.7978 - val_loss: 0.6581 - val_accuracy: 0.7406\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5205 - accuracy: 0.8072 - val_loss: 0.6420 - val_accuracy: 0.7456\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5047 - accuracy: 0.8134 - val_loss: 0.5828 - val_accuracy: 0.7844\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.5017 - accuracy: 0.8155 - val_loss: 0.7106 - val_accuracy: 0.7088\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4890 - accuracy: 0.8211 - val_loss: 0.6180 - val_accuracy: 0.7406\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4704 - accuracy: 0.8305 - val_loss: 0.7415 - val_accuracy: 0.6806\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4650 - accuracy: 0.8317 - val_loss: 0.6646 - val_accuracy: 0.7225\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4441 - accuracy: 0.8447 - val_loss: 0.6668 - val_accuracy: 0.7481\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4405 - accuracy: 0.8525 - val_loss: 0.6519 - val_accuracy: 0.7325\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4361 - accuracy: 0.8472 - val_loss: 0.5136 - val_accuracy: 0.8094\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.4221 - accuracy: 0.8619 - val_loss: 0.4980 - val_accuracy: 0.8281\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4070 - accuracy: 0.8612 - val_loss: 0.5104 - val_accuracy: 0.8125\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.4062 - accuracy: 0.8617 - val_loss: 0.4386 - val_accuracy: 0.8506\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3935 - accuracy: 0.8681 - val_loss: 0.6234 - val_accuracy: 0.7581\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3944 - accuracy: 0.8652 - val_loss: 0.5030 - val_accuracy: 0.8138\n",
            "Epoch 45/50\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3927 - accuracy: 0.8691 - val_loss: 0.6669 - val_accuracy: 0.7369\n",
            "Epoch 46/50\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.3741 - accuracy: 0.8739 - val_loss: 0.5054 - val_accuracy: 0.8156\n",
            "Epoch 47/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.3685 - accuracy: 0.8766 - val_loss: 0.7129 - val_accuracy: 0.7256\n",
            "Epoch 48/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.3649 - accuracy: 0.8839 - val_loss: 0.5058 - val_accuracy: 0.8156\n",
            "Epoch 49/50\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.3535 - accuracy: 0.8858 - val_loss: 0.4095 - val_accuracy: 0.8650\n",
            "Epoch 50/50\n",
            "100/100 [==============================] - 1s 5ms/step - loss: 0.3471 - accuracy: 0.8875 - val_loss: 0.4167 - val_accuracy: 0.8537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test).argmax(axis=1)\n",
        "print('Accuracy on test set - {0:.02%}'.format((pred == y_test).mean()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QByee6pEF2kd",
        "outputId": "02e00e16-8e20-4098-aab2-f7f76e45c27e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 2ms/step\n",
            "Accuracy on test set - 98.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model.fit(generator, epochs=100, batch_size=256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuSKgNEUsUx2",
        "outputId": "1be22329-26ef-44a2-9ac9-138aeecf5c31"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3490 - accuracy: 0.8914\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3477 - accuracy: 0.8930\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.3462 - accuracy: 0.8984\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3468 - accuracy: 0.8949\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3513 - accuracy: 0.8942\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3326 - accuracy: 0.8994\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 3s 93ms/step - loss: 0.3433 - accuracy: 0.8975\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 4s 109ms/step - loss: 0.3376 - accuracy: 0.8995\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3350 - accuracy: 0.9010\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 3s 104ms/step - loss: 0.3361 - accuracy: 0.9028\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 4s 118ms/step - loss: 0.3384 - accuracy: 0.8975\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3313 - accuracy: 0.9040\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3418 - accuracy: 0.9004\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 4s 126ms/step - loss: 0.3333 - accuracy: 0.9029\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3365 - accuracy: 0.9019\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3325 - accuracy: 0.8995\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3339 - accuracy: 0.9016\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 0.3328 - accuracy: 0.9004\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3380 - accuracy: 0.8975\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3358 - accuracy: 0.9035\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.3300 - accuracy: 0.9043\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3305 - accuracy: 0.9009\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3259 - accuracy: 0.9026\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.3386 - accuracy: 0.8971\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3398 - accuracy: 0.9020\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.3396 - accuracy: 0.8970\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 4s 114ms/step - loss: 0.3495 - accuracy: 0.8942\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3352 - accuracy: 0.8999\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3285 - accuracy: 0.9009\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 3s 101ms/step - loss: 0.3353 - accuracy: 0.9043\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3283 - accuracy: 0.9051\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3280 - accuracy: 0.9050\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 4s 132ms/step - loss: 0.3286 - accuracy: 0.9010\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3298 - accuracy: 0.9019\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3355 - accuracy: 0.9016\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3333 - accuracy: 0.9003\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 0.3386 - accuracy: 0.8997\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3236 - accuracy: 0.9043\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3159 - accuracy: 0.9031\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 4s 112ms/step - loss: 0.3278 - accuracy: 0.9034\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3212 - accuracy: 0.9026\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3333 - accuracy: 0.9025\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 4s 127ms/step - loss: 0.3304 - accuracy: 0.8991\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3267 - accuracy: 0.9022\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3205 - accuracy: 0.9060\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3235 - accuracy: 0.9046\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3202 - accuracy: 0.9066\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 4s 115ms/step - loss: 0.3285 - accuracy: 0.9028\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3357 - accuracy: 0.8995\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3320 - accuracy: 0.8997\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3233 - accuracy: 0.9074\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 4s 122ms/step - loss: 0.3279 - accuracy: 0.9059\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3197 - accuracy: 0.9046\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3157 - accuracy: 0.9049\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 4s 114ms/step - loss: 0.3136 - accuracy: 0.9085\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.3281 - accuracy: 0.9029\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3219 - accuracy: 0.9051\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 3s 99ms/step - loss: 0.3215 - accuracy: 0.9021\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3394 - accuracy: 0.9001\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3283 - accuracy: 0.9039\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 4s 132ms/step - loss: 0.3183 - accuracy: 0.9035\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3229 - accuracy: 0.9032\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3247 - accuracy: 0.9043\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 4s 138ms/step - loss: 0.3110 - accuracy: 0.9060\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3260 - accuracy: 0.9020\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3180 - accuracy: 0.9045\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.3159 - accuracy: 0.9036\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3136 - accuracy: 0.9071\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3215 - accuracy: 0.9022\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 4s 123ms/step - loss: 0.3110 - accuracy: 0.9095\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3201 - accuracy: 0.9040\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3156 - accuracy: 0.9066\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 3s 105ms/step - loss: 0.3099 - accuracy: 0.9076\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3145 - accuracy: 0.9084\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3196 - accuracy: 0.9040\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 3s 98ms/step - loss: 0.3210 - accuracy: 0.9034\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3196 - accuracy: 0.9064\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3143 - accuracy: 0.9122\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3206 - accuracy: 0.9021\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.3101 - accuracy: 0.9085\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3243 - accuracy: 0.9022\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3155 - accuracy: 0.9106\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.3248 - accuracy: 0.9031\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3177 - accuracy: 0.9079\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3103 - accuracy: 0.9096\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 3s 106ms/step - loss: 0.3139 - accuracy: 0.9051\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3096 - accuracy: 0.9095\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3293 - accuracy: 0.9024\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 3s 100ms/step - loss: 0.3086 - accuracy: 0.9105\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 4s 125ms/step - loss: 0.3152 - accuracy: 0.9103\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3058 - accuracy: 0.9122\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3187 - accuracy: 0.9084\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 4s 130ms/step - loss: 0.3074 - accuracy: 0.9099\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3014 - accuracy: 0.9101\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 3s 97ms/step - loss: 0.3160 - accuracy: 0.9105\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 4s 129ms/step - loss: 0.3080 - accuracy: 0.9070\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 3s 96ms/step - loss: 0.3149 - accuracy: 0.9101\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3088 - accuracy: 0.9072\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 4s 114ms/step - loss: 0.3089 - accuracy: 0.9085\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 3s 95ms/step - loss: 0.3138 - accuracy: 0.9084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "n1ftavTr66Ph"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}